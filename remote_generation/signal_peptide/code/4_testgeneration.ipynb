{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "from translator import SignalTranslator\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "with open('../outputs/ctable_token.pkl', 'rb') as f:\n",
    "    ctable = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.cuda.device at 0x7f2cf5b2e978>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions for tokenizing new inputs\n",
    "alphabet = ' .$ACDEFGHIKLMNPQRSTUVWXYZ'\n",
    "max_len_in = 107 # max length of prot seq (105 aa) + 2 for tokens\n",
    "max_len_out = 72\n",
    "n_chars = len(alphabet)\n",
    "\n",
    "with open('../data/ctable_copies/ctable_token_master.pkl', 'rb') as f:\n",
    "    ctable = pickle.load(f)\n",
    "\n",
    "def encode(seqs, max_len, ctable):\n",
    "    if ctable.one_hot:\n",
    "        X = np.zeros((len(seqs), max_len, n_chars))\n",
    "    else:\n",
    "        X = np.zeros((len(seqs), max_len))\n",
    "    seqs = ['$' + seq + '.' for seq in seqs]\n",
    "    seqs = [seq + ' ' * ((max_len) - len(seq))for seq in seqs]\n",
    "    for i, seq in enumerate(seqs):\n",
    "        X[i] = ctable.encode(seq, max_len)\n",
    "    return X\n",
    "\n",
    "def to_h5py(seqs, fname, ctable):\n",
    "    chunksize = 500\n",
    "    with h5py.File(fname, 'w') as f:\n",
    "        if ctable.one_hot:\n",
    "            print('true')\n",
    "            X = f.create_dataset('X', (len(seqs), max_len_in, n_chars))\n",
    "        else:\n",
    "            X = f.create_dataset('X', (len(seqs), max_len_in))          \n",
    "        for i in range(0, len(seqs), chunksize):\n",
    "            X[i:i + chunksize, :] = encode([seq for seq in seqs[i:i+chunksize]], max_len_in, ctable)\n",
    "        left = len(seqs) % chunksize\n",
    "        if left > 0:\n",
    "            X[-left:, :] = encode([seq for seq in seqs[-left:]], max_len_in, ctable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample input, convert to h5py file for generator\n",
    "df = pd.read_excel('../data/example_test_input.xlsx', engine='openpyxl')\n",
    "test_seqs = df['protein_sequence'].values\n",
    "test_seqs = [s[:100] for s in test_seqs]\n",
    "test_filename = ('../data/example_test_tokens.hdf5')\n",
    "to_h5py(test_seqs, test_filename, ctable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(cuda=False, d_inner_hid=1100, d_k=64, d_model=550, d_v=64, d_word_vec=550, dropout=0.1, embs_share_weight=True, max_token_seq_len=107, n_head=5, n_layers=6, proj_share_weight=True, src_vocab_size=27, tgt_vocab_size=27) Namespace(beam_size=1, ctable=<tools.CharacterTable object at 0x7f2cedbd9e48>, max_trans_length=72, n_best=1) Namespace(d_model=None, decay_power=-0.03, lr_max=0.0001, n_warmup_steps=12500, optim=<class 'torch.optim.adam.Adam'>)\n",
      "position_encoding\n",
      "position_encoding\n",
      "Initiated Transformer with 27403200 parameters.\n"
     ]
    }
   ],
   "source": [
    "# Load a Model Checkpoint\n",
    "chkpt_name = 'SIM99_550_12500_64_6_5_0.1_64_100_0.0001_-0.03_99'\n",
    "chkpt = \"../outputs/models/model_checkpoints/\" + chkpt_name + \".chkpt\"\n",
    "clf = SignalTranslator.load_model(chkpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anton/miniconda3/envs/pytorch_p36_clean_cuda/lib/python3.6/site-packages/torch/nn/modules/module.py:357: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  result = self.forward(*input, **kwargs)\n",
      "/home/anton/SPGen/remote_generation/signal_peptide/code/translator.py:377: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  out = self.model.prob_projection(dec_output)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MKKPLGKIVASTALLISVAFSSSIASA.\n",
      "\n",
      "MIKKIPLKTIAVMALSGCTFFVNG.\n",
      "\n",
      "MRLAKIAGLTASLLFSLWGALA.\n",
      "\n",
      "MAILVLLFLLAVEINS.\n",
      "\n",
      "MKMRTGKKGFLSILLAFLLVITSIPFTLVDVEA.\n",
      "\n",
      "MKLFTATIAVLGAVSATAHA.\n",
      "\n",
      "MKDLFRLIALLSCCLALFPLTFA.\n",
      "\n",
      "MKSLLLTAFAAGTALA.                                                       \n",
      "\n",
      "MNKLFYLFMLGLAAFA.                                                       \n",
      "\n",
      "MKLKIVFAVAAIAPVLHS.\n",
      "\n",
      "MKFTQAVLSLLGSAATALA.\n",
      "\n",
      "MNIRLGALLAGLLLSAMASAVFA.\n",
      "\n",
      "MKKSLISFLALGLLFGSAFA.\n",
      "\n",
      "MKFLSIVLLIVGLAYG.\n",
      "\n",
      "MFKFVLVLSVLAALASARA.\n",
      "\n",
      "MLTFHRIIRKGWMFLLAFLLTALLFCPTGQPAKA.\n",
      "\n",
      "MNLKILFALALGVCLAA.\n",
      "\n",
      "MVSNKRVLALSALFGCCSLASA.\n",
      "\n",
      "MKNFATLSAVLAGATALA.                                                     \n",
      "\n",
      "MIRLKRLLAGLLLPLFVTAFG.\n",
      "\n",
      "MKKTGFIGKTLALVIAAGMAGTAAFA.\n",
      "\n",
      "MKKTILALALLGSLAA.                                                       \n",
      "\n",
      "MTLKTTITLFFAALSANAAFA.\n",
      "\n",
      "MKFQDLTLVLSLSTALA.\n",
      "\n",
      "MKLLTSFVLIGALAFA.                                                       \n",
      "\n",
      "MGIQKKVSILVAGLFMATAFATA.\n",
      "\n",
      "MKKTAAIAALAGLSFAGMAHA.\n",
      "\n",
      "MVASLWSSILPVLAFLWADLSAGA.\n",
      "\n",
      "MKKRLLIASVALGSLFSFCA.\n",
      "\n",
      "MARA.\n",
      "\n",
      "MKFLILLITLGAIAATALA.\n",
      "\n",
      "MKLFKILTACLFIGLLNVSA.\n",
      "\n",
      "MKLSQSLTYLAVLGLAAGANA.\n",
      "\n",
      "MRSLLLTLLGALLRA.                                                        \n",
      "\n",
      "MKFLIPLFVLFIVFGNAYA.                                                    \n",
      "\n",
      "MKKRVISALAALWLSVLGAPAVLA.\n",
      "\n",
      "MTQKSLLLALTAVALVSVNA.\n",
      "\n",
      "MKGTLAFLLVFLLNLYVHG.\n",
      "\n",
      "MKCCRIMFVLLGLWFVFGLSVPGGRTEA.\n",
      "\n",
      "MKLLKVIATAFLGLTSFASA.\n",
      "\n",
      "MRSLLLTSALAALVSLAAASA.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test_gen_data = []\n",
    "# Generate SPs for Proteins\n",
    "file = h5py.File(test_filename)\n",
    "training_data = SignalTranslator.generator_from_h5_noy(file, 64, shuffle=False, use_cuda=False)\n",
    "src = next(training_data) # src is prot sequence, tgt is signal pep\n",
    "file.close()\n",
    "clf_outputs  = clf.translate_batch(src, 5)\n",
    "decoded, all_hyp, all_scores, enc_outputs, dec_outputs, enc_slf_attns, dec_slf_attns, dec_enc_attn = clf_outputs\n",
    "\n",
    "for src, dec in zip(src[0], decoded):\n",
    "#     print(ctable.decode(src.data.cpu().numpy())[:]) # prot sequence from Zach's excel\n",
    "    print(dec) # model's predictions\n",
    "    print()\n",
    "    \n",
    "    input_seq = ctable.decode(src.data.cpu().numpy())[:]\n",
    "    output_seq = dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
